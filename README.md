# ğŸ“§ C# Spam Classifier (v2 - Multinomial Naive Bayes)

Bu proje, C# ve .NET Core kullanÄ±larak **sÄ±fÄ±rdan (from scratch)** geliÅŸtirilmiÅŸ, harici bir ML kÃ¼tÃ¼phanesi kullanÄ±lmadan saf matematiksel mantÄ±kla Ã§alÄ±ÅŸan bir E-Posta Spam Filtresi uygulamasÄ±dÄ±r.

Proje, **Bernoulli** modelinden (v1) baÅŸlayÄ±p, dengesiz veri setlerinde daha baÅŸarÄ±lÄ± olan **Multinomial** modele (v2) evrilen bir Ã¶ÄŸrenme sÃ¼recinin Ã¼rÃ¼nÃ¼dÃ¼r.

## ğŸ¯ Proje KazanÄ±mlarÄ± ve MÃ¼hendislik Vizyonu
Bu proje sadece Ã§alÄ±ÅŸan bir kod parÃ§asÄ± deÄŸil, aynÄ± zamanda temel Yapay Zeka ve Veri MÃ¼hendisliÄŸi kavramlarÄ±nÄ±n derinlemesine analizidir:

* **Matematiksel Sezgi (Mathematical Intuition):** Bayes Teoremi'nin sadece bir formÃ¼l olmadÄ±ÄŸÄ±; yeni kanÄ±tlarla (kelimelerle) mevcut inancÄ±n (Spam/Ham olasÄ±lÄ±ÄŸÄ±) nasÄ±l gÃ¼ncellendiÄŸi kod Ã¼zerinde simÃ¼le edildi.
* **Veri MÃ¼hendisliÄŸi (Data Engineering):** Ham verinin (CSV) iÅŸlenebilir formata (JSON) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi, ETL sÃ¼reÃ§leri ve veri temizliÄŸi (Tokenization, Case-folding) iÅŸlemleri manuel olarak yÃ¶netildi.
* **Algoritmik Problem Ã‡Ã¶zme:**
    * **Underflow Problemi:** Ã‡ok kÃ¼Ã§Ã¼k olasÄ±lÄ±klarÄ±n Ã§arpÄ±mÄ± sonucu oluÅŸan veri kaybÄ±, **Log-Sum-Exp** yÃ¶ntemiyle (Ã§arpma yerine logaritma toplama) Ã§Ã¶zÃ¼ldÃ¼.
    * **Zero Probability:** HiÃ§ gÃ¶rÃ¼lmemiÅŸ kelimelerin sistemi Ã§Ã¶kertmemesi iÃ§in **Laplace Smoothing** uygulandÄ±.
    * **Model Optimizasyonu:** "Rare Word Paradox" hatasÄ± tespit edilerek, kelime varlÄ±ÄŸÄ±na bakan Bernoulli modelinden, kelime frekansÄ±na ve havuz yoÄŸunluÄŸuna bakan Multinomial modele geÃ§iÅŸ yapÄ±ldÄ±.

## ğŸ› ï¸ Teknik Detaylar (v2)
* **Algoritma:** Multinomial Naive Bayes
* **Dil:** C# (.NET 8.0)
* **Veri YapÄ±sÄ±:** `Dictionary<string, int>` (Frekans SayÄ±mÄ±) ve `HashSet` (Vocabulary)
* **YumuÅŸatma (Smoothing):** Paydaya `Vocabulary Size` eklenerek nadir kelimelerin aÄŸÄ±rlÄ±ÄŸÄ± dengelendi.

### FormÃ¼l (Multinomial)
Her bir kelimenin skor katkÄ±sÄ± ÅŸu ÅŸekilde hesaplanÄ±r:

$$\text{Score} += \log \left( \frac{\text{Kelime FrekansÄ±} + 1}{\text{Toplam Token SayÄ±sÄ±} + \text{Vocabulary Size}} \right)$$

## ğŸ”„ SÃ¼rÃ¼m GeÃ§miÅŸi

### v2 (GÃ¼ncel - Stable) âœ…
* **YÃ¶ntem:** Kelime frekanslarÄ± dikkate alÄ±nÄ±r (Frequency-based).
* **Ä°yileÅŸtirme:** Paydaya toplam kelime daÄŸarcÄ±ÄŸÄ± (Vocabulary Size) eklendi.
* **SonuÃ§:** Dengesiz veri setlerinde (Imbalanced Dataset) oluÅŸan "False Positive" hatalarÄ± giderildi. "Project meeting" gibi nadir kelimeler iÃ§eren normal mesajlar artÄ±k doÄŸru sÄ±nÄ±flandÄ±rÄ±lÄ±yor.

### v1 (Eski SÃ¼rÃ¼m) âš ï¸
* **YÃ¶ntem:** Bernoulli Naive Bayes (Kelime var/yok).
* **Sorun:** Spam mesaj sayÄ±sÄ± az olduÄŸunda, nadir gÃ¶rÃ¼len kelimeler matematiksel olarak Spam ihtimalini yapay ÅŸekilde yÃ¼kseltiyordu (Rare Word Paradox).

